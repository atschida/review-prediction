{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>cust_review_count</th>\n",
       "      <th>cust_star_rating_mean</th>\n",
       "      <th>cust_star_rating_std</th>\n",
       "      <th>prod_review_count</th>\n",
       "      <th>prod_star_rating_mean</th>\n",
       "      <th>prod_star_rating_std</th>\n",
       "      <th>pos_sim</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_3_word_3</th>\n",
       "      <th>neg_1_word_1</th>\n",
       "      <th>neg_1_word_2</th>\n",
       "      <th>neg_1_word_3</th>\n",
       "      <th>neg_2_word_1</th>\n",
       "      <th>neg_2_word_2</th>\n",
       "      <th>neg_2_word_3</th>\n",
       "      <th>neg_3_word_1</th>\n",
       "      <th>neg_3_word_2</th>\n",
       "      <th>neg_3_word_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1617361</td>\n",
       "      <td>849246716</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>297</td>\n",
       "      <td>4.872054</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.033451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53052607</td>\n",
       "      <td>849246716</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>297</td>\n",
       "      <td>4.872054</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.012478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028547</td>\n",
       "      <td>0.172017</td>\n",
       "      <td>0.084518</td>\n",
       "      <td>0.194290</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>0.052950</td>\n",
       "      <td>0.344210</td>\n",
       "      <td>0.307019</td>\n",
       "      <td>0.363920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15679577</td>\n",
       "      <td>849246716</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>1.505941</td>\n",
       "      <td>297</td>\n",
       "      <td>4.872054</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.007220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.371702</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.316641</td>\n",
       "      <td>0.156807</td>\n",
       "      <td>0.052990</td>\n",
       "      <td>0.165214</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>-0.066285</td>\n",
       "      <td>-0.171195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16367779</td>\n",
       "      <td>849246716</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>0.527046</td>\n",
       "      <td>297</td>\n",
       "      <td>4.872054</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25485198</td>\n",
       "      <td>849246716</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>297</td>\n",
       "      <td>4.872054</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_parent  star_rating  cust_review_count  \\\n",
       "0      1617361       849246716            5                  5   \n",
       "1     53052607       849246716            3                  5   \n",
       "2     15679577       849246716            5                  8   \n",
       "3     16367779       849246716            5                  9   \n",
       "4     25485198       849246716            5                 17   \n",
       "\n",
       "   cust_star_rating_mean  cust_star_rating_std  prod_review_count  \\\n",
       "0               5.000000              0.000000                297   \n",
       "1               3.600000              0.547723                297   \n",
       "2               3.375000              1.505941                297   \n",
       "3               4.444444              0.527046                297   \n",
       "4               5.000000              0.000000                297   \n",
       "\n",
       "   prod_star_rating_mean  prod_star_rating_std   pos_sim  ...  pos_3_word_3  \\\n",
       "0               4.872054              0.363625  0.033451  ...      0.186957   \n",
       "1               4.872054              0.363625  0.012478  ...     -0.028547   \n",
       "2               4.872054              0.363625  0.007220  ...      0.044000   \n",
       "3               4.872054              0.363625  0.095238  ...     -0.171195   \n",
       "4               4.872054              0.363625  0.010870  ...      0.249734   \n",
       "\n",
       "   neg_1_word_1  neg_1_word_2  neg_1_word_3  neg_2_word_1  neg_2_word_2  \\\n",
       "0      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "1      0.172017      0.084518      0.194290      0.002472      0.006273   \n",
       "2      0.371702      0.000015      0.316641      0.156807      0.052990   \n",
       "3      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "4      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "\n",
       "   neg_2_word_3  neg_3_word_1  neg_3_word_2  neg_3_word_3  \n",
       "0      0.000000      0.000000      0.000000      0.000000  \n",
       "1      0.052950      0.344210      0.307019      0.363920  \n",
       "2      0.165214      0.011699     -0.066285     -0.171195  \n",
       "3      0.000000      0.000000      0.000000      0.000000  \n",
       "4      0.000000      0.000000      0.000000      0.000000  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_df2.csv', index_col=0)\n",
    "train_df.drop(['positive', 'pos_corpus', 'neg_corpus', 'pos_1', 'pos_2', 'pos_3', \n",
    "               'neg_1', 'neg_2', 'neg_3', 'prod_corpus', 'word_1', 'word_2', 'word_3'], axis=1, inplace=True)\n",
    "train_df.drop(['cust_total_votes_mean', 'cust_total_votes_std', 'cust_helpful_votes_mean', 'cust_helpful_votes_std', \n",
    "               'prod_total_votes_mean', 'prod_total_votes_std', 'prod_helpful_votes_mean', 'prod_helpful_votes_std'], \n",
    "              axis=1, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'product_parent', 'star_rating', 'cust_review_count',\n",
       "       'cust_star_rating_mean', 'cust_star_rating_std', 'prod_review_count',\n",
       "       'prod_star_rating_mean', 'prod_star_rating_std', 'pos_sim', 'neg_sim',\n",
       "       'pos_1_word_1', 'pos_1_word_2', 'pos_1_word_3', 'pos_2_word_1',\n",
       "       'pos_2_word_2', 'pos_2_word_3', 'pos_3_word_1', 'pos_3_word_2',\n",
       "       'pos_3_word_3', 'neg_1_word_1', 'neg_1_word_2', 'neg_1_word_3',\n",
       "       'neg_2_word_1', 'neg_2_word_2', 'neg_2_word_3', 'neg_3_word_1',\n",
       "       'neg_3_word_2', 'neg_3_word_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "star_rating\n",
       "1     3431\n",
       "2     2299\n",
       "3     3801\n",
       "4     7972\n",
       "5    30219\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('star_rating').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_df[train_df.star_rating == 1][:3324]\n",
    "temp = pd.concat([temp, train_df[train_df.star_rating == 2]])\n",
    "temp = pd.concat([temp, train_df[train_df.star_rating == 3]])\n",
    "temp = pd.concat([temp, train_df[train_df.star_rating == 4][:len(train_df[train_df.star_rating == 4]) // 2]])\n",
    "temp = pd.concat([temp, train_df[train_df.star_rating == 5][:len(train_df[train_df.star_rating == 5]) // 8]])\n",
    "train_df = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "star_rating\n",
       "1    0.193402\n",
       "2    0.133764\n",
       "3    0.221156\n",
       "4    0.231919\n",
       "5    0.219759\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('star_rating').size() / len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>cust_review_count</th>\n",
       "      <th>cust_star_rating_mean</th>\n",
       "      <th>cust_star_rating_std</th>\n",
       "      <th>prod_review_count</th>\n",
       "      <th>prod_star_rating_mean</th>\n",
       "      <th>prod_star_rating_std</th>\n",
       "      <th>pos_sim</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_3_word_3</th>\n",
       "      <th>neg_1_word_1</th>\n",
       "      <th>neg_1_word_2</th>\n",
       "      <th>neg_1_word_3</th>\n",
       "      <th>neg_2_word_1</th>\n",
       "      <th>neg_2_word_2</th>\n",
       "      <th>neg_2_word_3</th>\n",
       "      <th>neg_3_word_1</th>\n",
       "      <th>neg_3_word_2</th>\n",
       "      <th>neg_3_word_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36330222</td>\n",
       "      <td>986428010</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>4.291667</td>\n",
       "      <td>1.267629</td>\n",
       "      <td>18</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.188177</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>-0.015594</td>\n",
       "      <td>-0.013630</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.023873</td>\n",
       "      <td>-0.029103</td>\n",
       "      <td>-0.046843</td>\n",
       "      <td>-0.041810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24360083</td>\n",
       "      <td>986428010</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>1.191206</td>\n",
       "      <td>18</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.188177</td>\n",
       "      <td>0.095361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901494</td>\n",
       "      <td>-0.222196</td>\n",
       "      <td>-0.196039</td>\n",
       "      <td>-0.217517</td>\n",
       "      <td>0.918800</td>\n",
       "      <td>0.925143</td>\n",
       "      <td>0.901494</td>\n",
       "      <td>0.919331</td>\n",
       "      <td>0.902017</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28891040</td>\n",
       "      <td>437083384</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>407</td>\n",
       "      <td>4.503686</td>\n",
       "      <td>0.887439</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092532</td>\n",
       "      <td>0.313854</td>\n",
       "      <td>0.086877</td>\n",
       "      <td>0.315884</td>\n",
       "      <td>0.196752</td>\n",
       "      <td>0.052950</td>\n",
       "      <td>0.194290</td>\n",
       "      <td>0.054040</td>\n",
       "      <td>0.014332</td>\n",
       "      <td>-0.002904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52449052</td>\n",
       "      <td>437083384</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1.516575</td>\n",
       "      <td>407</td>\n",
       "      <td>4.503686</td>\n",
       "      <td>0.887439</td>\n",
       "      <td>0.010390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187860</td>\n",
       "      <td>0.083284</td>\n",
       "      <td>-0.115922</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.090283</td>\n",
       "      <td>-0.083403</td>\n",
       "      <td>0.025464</td>\n",
       "      <td>0.084633</td>\n",
       "      <td>-0.092710</td>\n",
       "      <td>0.019767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27192976</td>\n",
       "      <td>437083384</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>407</td>\n",
       "      <td>4.503686</td>\n",
       "      <td>0.887439</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126235</td>\n",
       "      <td>-0.083963</td>\n",
       "      <td>0.036128</td>\n",
       "      <td>-0.155615</td>\n",
       "      <td>-0.020984</td>\n",
       "      <td>0.021015</td>\n",
       "      <td>-0.042505</td>\n",
       "      <td>0.059809</td>\n",
       "      <td>-0.017769</td>\n",
       "      <td>-0.064662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_parent  star_rating  cust_review_count  \\\n",
       "0     36330222       986428010            5                 24   \n",
       "1     24360083       986428010            4                 23   \n",
       "2     28891040       437083384            4                 10   \n",
       "3     52449052       437083384            3                  5   \n",
       "4     27192976       437083384            4                  6   \n",
       "\n",
       "   cust_star_rating_mean  cust_star_rating_std  prod_review_count  \\\n",
       "0               4.291667              1.267629                 18   \n",
       "1               4.347826              1.191206                 18   \n",
       "2               4.500000              0.707107                407   \n",
       "3               3.400000              1.516575                407   \n",
       "4               4.666667              0.816497                407   \n",
       "\n",
       "   prod_star_rating_mean  prod_star_rating_std   pos_sim  ...  pos_3_word_3  \\\n",
       "0               4.333333              1.188177  0.070423  ...      0.001941   \n",
       "1               4.333333              1.188177  0.095361  ...      0.901494   \n",
       "2               4.503686              0.887439  0.006944  ...      0.092532   \n",
       "3               4.503686              0.887439  0.010390  ...      0.187860   \n",
       "4               4.503686              0.887439  0.012942  ...      0.126235   \n",
       "\n",
       "   neg_1_word_1  neg_1_word_2  neg_1_word_3  neg_2_word_1  neg_2_word_2  \\\n",
       "0      0.000987     -0.015594     -0.013630      0.006534      0.007653   \n",
       "1     -0.222196     -0.196039     -0.217517      0.918800      0.925143   \n",
       "2      0.313854      0.086877      0.315884      0.196752      0.052950   \n",
       "3      0.083284     -0.115922      0.023810      0.090283     -0.083403   \n",
       "4     -0.083963      0.036128     -0.155615     -0.020984      0.021015   \n",
       "\n",
       "   neg_2_word_3  neg_3_word_1  neg_3_word_2  neg_3_word_3  \n",
       "0      0.023873     -0.029103     -0.046843     -0.041810  \n",
       "1      0.901494      0.919331      0.902017      1.000000  \n",
       "2      0.194290      0.054040      0.014332     -0.002904  \n",
       "3      0.025464      0.084633     -0.092710      0.019767  \n",
       "4     -0.042505      0.059809     -0.017769     -0.064662  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_df2.csv', index_col=0)\n",
    "test_df.drop(['positive', 'pos_corpus', 'neg_corpus', 'pos_1', 'pos_2', 'pos_3', \n",
    "               'neg_1', 'neg_2', 'neg_3', 'prod_corpus', 'word_1', 'word_2', 'word_3'], axis=1, inplace=True)\n",
    "test_df.drop(['cust_total_votes_mean', 'cust_total_votes_std', 'cust_helpful_votes_mean', 'cust_helpful_votes_std', \n",
    "               'prod_total_votes_mean', 'prod_total_votes_std', 'prod_helpful_votes_mean', 'prod_helpful_votes_std'], \n",
    "              axis=1, inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5701294600568361"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.query('star_rating == 5')) / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train_df[['customer_id', 'product_parent', 'star_rating', 'pos_sim', 'neg_sim',\n",
    "        'pos_2_word_1', 'pos_2_word_2', 'pos_2_word_3', 'pos_3_word_1',\n",
    "        'pos_3_word_2', 'pos_3_word_3', 'neg_1_word_1', 'neg_1_word_2',\n",
    "        'neg_1_word_3', 'neg_2_word_1', 'neg_2_word_2', 'neg_2_word_3',\n",
    "        'neg_3_word_1', 'neg_3_word_2', 'neg_3_word_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>cust_review_count</th>\n",
       "      <th>cust_star_rating_mean</th>\n",
       "      <th>cust_star_rating_std</th>\n",
       "      <th>prod_review_count</th>\n",
       "      <th>prod_star_rating_mean</th>\n",
       "      <th>prod_star_rating_std</th>\n",
       "      <th>pos_sim</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_3_word_3</th>\n",
       "      <th>neg_1_word_1</th>\n",
       "      <th>neg_1_word_2</th>\n",
       "      <th>neg_1_word_3</th>\n",
       "      <th>neg_2_word_1</th>\n",
       "      <th>neg_2_word_2</th>\n",
       "      <th>neg_2_word_3</th>\n",
       "      <th>neg_3_word_1</th>\n",
       "      <th>neg_3_word_2</th>\n",
       "      <th>neg_3_word_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1617361</td>\n",
       "      <td>849246716</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047284</td>\n",
       "      <td>0.968013</td>\n",
       "      <td>0.128561</td>\n",
       "      <td>0.033451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53052607</td>\n",
       "      <td>849246716</td>\n",
       "      <td>3</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.237171</td>\n",
       "      <td>0.047284</td>\n",
       "      <td>0.968013</td>\n",
       "      <td>0.128561</td>\n",
       "      <td>0.012478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028547</td>\n",
       "      <td>0.172017</td>\n",
       "      <td>0.084518</td>\n",
       "      <td>0.194290</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>0.052950</td>\n",
       "      <td>0.344210</td>\n",
       "      <td>0.307019</td>\n",
       "      <td>0.363920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15679577</td>\n",
       "      <td>849246716</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.652091</td>\n",
       "      <td>0.047284</td>\n",
       "      <td>0.968013</td>\n",
       "      <td>0.128561</td>\n",
       "      <td>0.007220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.371702</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.316641</td>\n",
       "      <td>0.156807</td>\n",
       "      <td>0.052990</td>\n",
       "      <td>0.165214</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>-0.066285</td>\n",
       "      <td>-0.171195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16367779</td>\n",
       "      <td>849246716</td>\n",
       "      <td>5</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.228218</td>\n",
       "      <td>0.047284</td>\n",
       "      <td>0.968013</td>\n",
       "      <td>0.128561</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25485198</td>\n",
       "      <td>849246716</td>\n",
       "      <td>5</td>\n",
       "      <td>0.066964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047284</td>\n",
       "      <td>0.968013</td>\n",
       "      <td>0.128561</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_parent  star_rating  cust_review_count  \\\n",
       "0      1617361       849246716            5           0.013393   \n",
       "1     53052607       849246716            3           0.013393   \n",
       "2     15679577       849246716            5           0.026786   \n",
       "3     16367779       849246716            5           0.031250   \n",
       "4     25485198       849246716            5           0.066964   \n",
       "\n",
       "   cust_star_rating_mean  cust_star_rating_std  prod_review_count  \\\n",
       "0               1.000000              0.000000           0.047284   \n",
       "1               0.650000              0.237171           0.047284   \n",
       "2               0.593750              0.652091           0.047284   \n",
       "3               0.861111              0.228218           0.047284   \n",
       "4               1.000000              0.000000           0.047284   \n",
       "\n",
       "   prod_star_rating_mean  prod_star_rating_std   pos_sim  ...  pos_3_word_3  \\\n",
       "0               0.968013              0.128561  0.033451  ...      0.186957   \n",
       "1               0.968013              0.128561  0.012478  ...     -0.028547   \n",
       "2               0.968013              0.128561  0.007220  ...      0.044000   \n",
       "3               0.968013              0.128561  0.095238  ...     -0.171195   \n",
       "4               0.968013              0.128561  0.010870  ...      0.249734   \n",
       "\n",
       "   neg_1_word_1  neg_1_word_2  neg_1_word_3  neg_2_word_1  neg_2_word_2  \\\n",
       "0      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "1      0.172017      0.084518      0.194290      0.002472      0.006273   \n",
       "2      0.371702      0.000015      0.316641      0.156807      0.052990   \n",
       "3      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "4      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "\n",
       "   neg_2_word_3  neg_3_word_1  neg_3_word_2  neg_3_word_3  \n",
       "0      0.000000      0.000000      0.000000      0.000000  \n",
       "1      0.052950      0.344210      0.307019      0.363920  \n",
       "2      0.165214      0.011699     -0.066285     -0.171195  \n",
       "3      0.000000      0.000000      0.000000      0.000000  \n",
       "4      0.000000      0.000000      0.000000      0.000000  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "train_df_norm = pd.DataFrame(min_max_scaler.fit_transform(train_df), columns=train_df.columns, index=train_df.index)\n",
    "train_df_norm[['customer_id', 'product_parent', 'star_rating', 'pos_sim', 'neg_sim',\n",
    "        'pos_2_word_1', 'pos_2_word_2', 'pos_2_word_3', 'pos_3_word_1',\n",
    "        'pos_3_word_2', 'pos_3_word_3', 'neg_1_word_1', 'neg_1_word_2',\n",
    "        'neg_1_word_3', 'neg_2_word_1', 'neg_2_word_2', 'neg_2_word_3',\n",
    "        'neg_3_word_1', 'neg_3_word_2', 'neg_3_word_3']] = train_ids\n",
    "train_df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test_df[['customer_id', 'product_parent', 'star_rating', 'pos_sim', 'neg_sim',\n",
    "        'pos_2_word_1', 'pos_2_word_2', 'pos_2_word_3', 'pos_3_word_1',\n",
    "        'pos_3_word_2', 'pos_3_word_3', 'neg_1_word_1', 'neg_1_word_2',\n",
    "        'neg_1_word_3', 'neg_2_word_1', 'neg_2_word_2', 'neg_2_word_3',\n",
    "        'neg_3_word_1', 'neg_3_word_2', 'neg_3_word_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>cust_review_count</th>\n",
       "      <th>cust_star_rating_mean</th>\n",
       "      <th>cust_star_rating_std</th>\n",
       "      <th>prod_review_count</th>\n",
       "      <th>prod_star_rating_mean</th>\n",
       "      <th>prod_star_rating_std</th>\n",
       "      <th>pos_sim</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_3_word_3</th>\n",
       "      <th>neg_1_word_1</th>\n",
       "      <th>neg_1_word_2</th>\n",
       "      <th>neg_1_word_3</th>\n",
       "      <th>neg_2_word_1</th>\n",
       "      <th>neg_2_word_2</th>\n",
       "      <th>neg_2_word_3</th>\n",
       "      <th>neg_3_word_1</th>\n",
       "      <th>neg_3_word_2</th>\n",
       "      <th>neg_3_word_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36330222</td>\n",
       "      <td>986428010</td>\n",
       "      <td>5</td>\n",
       "      <td>0.098214</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.548900</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.420084</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>-0.015594</td>\n",
       "      <td>-0.013630</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.023873</td>\n",
       "      <td>-0.029103</td>\n",
       "      <td>-0.046843</td>\n",
       "      <td>-0.041810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24360083</td>\n",
       "      <td>986428010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.515807</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.420084</td>\n",
       "      <td>0.095361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901494</td>\n",
       "      <td>-0.222196</td>\n",
       "      <td>-0.196039</td>\n",
       "      <td>-0.217517</td>\n",
       "      <td>0.918800</td>\n",
       "      <td>0.925143</td>\n",
       "      <td>0.901494</td>\n",
       "      <td>0.919331</td>\n",
       "      <td>0.902017</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28891040</td>\n",
       "      <td>437083384</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.306186</td>\n",
       "      <td>0.064856</td>\n",
       "      <td>0.875921</td>\n",
       "      <td>0.313757</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092532</td>\n",
       "      <td>0.313854</td>\n",
       "      <td>0.086877</td>\n",
       "      <td>0.315884</td>\n",
       "      <td>0.196752</td>\n",
       "      <td>0.052950</td>\n",
       "      <td>0.194290</td>\n",
       "      <td>0.054040</td>\n",
       "      <td>0.014332</td>\n",
       "      <td>-0.002904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52449052</td>\n",
       "      <td>437083384</td>\n",
       "      <td>3</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.656696</td>\n",
       "      <td>0.064856</td>\n",
       "      <td>0.875921</td>\n",
       "      <td>0.313757</td>\n",
       "      <td>0.010390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187860</td>\n",
       "      <td>0.083284</td>\n",
       "      <td>-0.115922</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.090283</td>\n",
       "      <td>-0.083403</td>\n",
       "      <td>0.025464</td>\n",
       "      <td>0.084633</td>\n",
       "      <td>-0.092710</td>\n",
       "      <td>0.019767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27192976</td>\n",
       "      <td>437083384</td>\n",
       "      <td>4</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.064856</td>\n",
       "      <td>0.875921</td>\n",
       "      <td>0.313757</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126235</td>\n",
       "      <td>-0.083963</td>\n",
       "      <td>0.036128</td>\n",
       "      <td>-0.155615</td>\n",
       "      <td>-0.020984</td>\n",
       "      <td>0.021015</td>\n",
       "      <td>-0.042505</td>\n",
       "      <td>0.059809</td>\n",
       "      <td>-0.017769</td>\n",
       "      <td>-0.064662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_parent  star_rating  cust_review_count  \\\n",
       "0     36330222       986428010            5           0.098214   \n",
       "1     24360083       986428010            4           0.093750   \n",
       "2     28891040       437083384            4           0.035714   \n",
       "3     52449052       437083384            3           0.013393   \n",
       "4     27192976       437083384            4           0.017857   \n",
       "\n",
       "   cust_star_rating_mean  cust_star_rating_std  prod_review_count  \\\n",
       "0               0.822917              0.548900           0.002716   \n",
       "1               0.836957              0.515807           0.002716   \n",
       "2               0.875000              0.306186           0.064856   \n",
       "3               0.600000              0.656696           0.064856   \n",
       "4               0.916667              0.353553           0.064856   \n",
       "\n",
       "   prod_star_rating_mean  prod_star_rating_std   pos_sim  ...  pos_3_word_3  \\\n",
       "0               0.833333              0.420084  0.070423  ...      0.001941   \n",
       "1               0.833333              0.420084  0.095361  ...      0.901494   \n",
       "2               0.875921              0.313757  0.006944  ...      0.092532   \n",
       "3               0.875921              0.313757  0.010390  ...      0.187860   \n",
       "4               0.875921              0.313757  0.012942  ...      0.126235   \n",
       "\n",
       "   neg_1_word_1  neg_1_word_2  neg_1_word_3  neg_2_word_1  neg_2_word_2  \\\n",
       "0      0.000987     -0.015594     -0.013630      0.006534      0.007653   \n",
       "1     -0.222196     -0.196039     -0.217517      0.918800      0.925143   \n",
       "2      0.313854      0.086877      0.315884      0.196752      0.052950   \n",
       "3      0.083284     -0.115922      0.023810      0.090283     -0.083403   \n",
       "4     -0.083963      0.036128     -0.155615     -0.020984      0.021015   \n",
       "\n",
       "   neg_2_word_3  neg_3_word_1  neg_3_word_2  neg_3_word_3  \n",
       "0      0.023873     -0.029103     -0.046843     -0.041810  \n",
       "1      0.901494      0.919331      0.902017      1.000000  \n",
       "2      0.194290      0.054040      0.014332     -0.002904  \n",
       "3      0.025464      0.084633     -0.092710      0.019767  \n",
       "4     -0.042505      0.059809     -0.017769     -0.064662  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_norm = pd.DataFrame(min_max_scaler.transform(test_df), columns=test_df.columns, index=test_df.index)\n",
    "test_df_norm[['customer_id', 'product_parent', 'star_rating', 'pos_sim', 'neg_sim',\n",
    "        'pos_2_word_1', 'pos_2_word_2', 'pos_2_word_3', 'pos_3_word_1',\n",
    "        'pos_3_word_2', 'pos_3_word_3', 'neg_1_word_1', 'neg_1_word_2',\n",
    "        'neg_1_word_3', 'neg_2_word_1', 'neg_2_word_2', 'neg_2_word_3',\n",
    "        'neg_3_word_1', 'neg_3_word_2', 'neg_3_word_3']] = test_ids\n",
    "test_df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train_df.drop('star_rating', axis=1), train_df['star_rating']\n",
    "test_x, test_y = test_df.drop('star_rating', axis=1), test_df['star_rating']\n",
    "train_x_norm = train_df_norm.drop('star_rating', axis=1)\n",
    "test_x_norm = test_df.drop('star_rating', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>cust_review_count</th>\n",
       "      <th>cust_star_rating_mean</th>\n",
       "      <th>cust_star_rating_std</th>\n",
       "      <th>prod_review_count</th>\n",
       "      <th>prod_star_rating_mean</th>\n",
       "      <th>prod_star_rating_std</th>\n",
       "      <th>pos_sim</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_3_word_3</th>\n",
       "      <th>neg_1_word_1</th>\n",
       "      <th>neg_1_word_2</th>\n",
       "      <th>neg_1_word_3</th>\n",
       "      <th>neg_2_word_1</th>\n",
       "      <th>neg_2_word_2</th>\n",
       "      <th>neg_2_word_3</th>\n",
       "      <th>neg_3_word_1</th>\n",
       "      <th>neg_3_word_2</th>\n",
       "      <th>neg_3_word_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [customer_id, product_parent, star_rating, cust_review_count, cust_star_rating_mean, cust_star_rating_std, prod_review_count, prod_star_rating_mean, prod_star_rating_std, pos_sim, neg_sim, pos_1_word_1, pos_1_word_2, pos_1_word_3, pos_2_word_1, pos_2_word_2, pos_2_word_3, pos_3_word_1, pos_3_word_2, pos_3_word_3, neg_1_word_1, neg_1_word_2, neg_1_word_3, neg_2_word_1, neg_2_word_2, neg_2_word_3, neg_3_word_1, neg_3_word_2, neg_3_word_3]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_NaN = train_df_norm.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "train_df_norm[row_has_NaN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(train_x_norm.drop(['customer_id', 'product_parent'], axis=1), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44218503315440477"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.score(test_x_norm.drop(['customer_id', 'product_parent'], axis=1), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(train_x.drop(['customer_id', 'product_parent'], axis=1), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5873065993053362"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(test_x.drop(['customer_id', 'product_parent'], axis=1), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 26 artists>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp_tuples = sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), \n",
    "                 train_x.drop(['customer_id', 'product_parent'], axis=1).columns), reverse=False)\n",
    "imp = [t[0] for t in imp_tuples]\n",
    "labl = [t[1] for t in imp_tuples]\n",
    "plt.barh(labl, imp, linewidth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "knn.fit(train_x_norm.drop(['customer_id', 'product_parent'], axis=1), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5544679507420271"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(test_x_norm.drop(['customer_id', 'product_parent'], axis=1), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_x_norm.drop(['customer_id', 'product_parent'], axis=1), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42968108620145246"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.score(test_x_norm.drop(['customer_id', 'product_parent'], axis=1), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 12502 0.7895168929586359\n",
      "Pos: 15221 0.9612251341964004\n",
      "Star Correct: 9300 0.5873065993053362\n",
      "True Positive: 12075 0.7625513103883802\n",
      "True Negative: 427 0.02696558257025576\n",
      "False Positive: 3146 0.1986738238080202\n",
      "False Negative: 187 0.011809283233343858\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "pos_count = 0\n",
    "star_cor = 0\n",
    "matrix = [0, 0, 0, 0]\n",
    "preds = rf.predict(test_x.drop(['customer_id', 'product_parent'], axis=1))\n",
    "for i, row in test_df.iterrows():\n",
    "    if (preds[i] > 3):\n",
    "        pos_count += 1\n",
    "    if (preds[i] == row.star_rating):\n",
    "        star_cor += 1\n",
    "    if (preds[i] > 3 and row.star_rating > 3):\n",
    "        correct += 1\n",
    "        matrix[0] += 1\n",
    "    elif (preds[i] <= 3 and row.star_rating <= 3):\n",
    "        correct += 1\n",
    "        matrix[1] += 1\n",
    "    elif (preds[i] > 3 and row.star_rating <= 3):\n",
    "        matrix[2] += 1\n",
    "    elif (preds[i] <= 3 and row.star_rating > 3):\n",
    "        matrix[3] += 1\n",
    "\n",
    "print('Correct:', correct, correct / len(test_df))\n",
    "print('Pos:', pos_count, pos_count / len(test_df))\n",
    "print('Star Correct:', star_cor, star_cor / len(test_df))\n",
    "print('True Positive:', matrix[0], matrix[0] / len(test_df))\n",
    "print('True Negative:', matrix[1], matrix[1] / len(test_df))\n",
    "print('False Positive:', matrix[2], matrix[2] / len(test_df))\n",
    "print('False Negative:', matrix[3], matrix[3] / len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_train_x = train_x_norm.drop(['customer_id', 'product_parent'], axis=1)\n",
    "nn_test_x = test_x_norm.drop(['customer_id', 'product_parent'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47722, 26)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(nn_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_cat = to_categorical(train_y)\n",
    "test_y_cat = to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              27648     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 3,506,566\n",
      "Trainable params: 3,506,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(1024, activation='relu', input_shape=(26,)))\n",
    "#network.add(layers.Dropout(0.5))\n",
    "network.add(layers.Dense(1024, activation='relu', input_shape=(1024,)))\n",
    "network.add(layers.Dense(1024, activation='relu', input_shape=(1024,)))\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(1024,)))\n",
    "#network.add(layers.Dropout(0.5))\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(512,)))\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(512,)))\n",
    "network.add(layers.Dense(256, activation='relu', input_shape=(512,)))\n",
    "#network.add(layers.Dropout(0.5))\n",
    "network.add(layers.Dense(256, activation='relu', input_shape=(256,)))\n",
    "network.add(layers.Dense(256, activation='relu', input_shape=(256,)))\n",
    "network.add(layers.Dense(128, activation='relu', input_shape=(256,)))\n",
    "#network.add(layers.Dropout(0.5))\n",
    "network.add(layers.Dense(128, activation='relu', input_shape=(128,)))\n",
    "network.add(layers.Dense(128, activation='relu', input_shape=(128,)))\n",
    "network.add(layers.Dense(6, activation='softmax', input_shape=(128,)))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47722 samples, validate on 15835 samples\n",
      "Epoch 1/15\n",
      "47722/47722 [==============================] - 8s 160us/step - loss: 1.1265 - accuracy: 0.6321 - val_loss: 80.7984 - val_accuracy: 0.5701\n",
      "Epoch 2/15\n",
      "47722/47722 [==============================] - 3s 56us/step - loss: 1.0647 - accuracy: 0.6343 - val_loss: 143.8002 - val_accuracy: 0.5701\n",
      "Epoch 3/15\n",
      "47722/47722 [==============================] - 3s 55us/step - loss: 1.0535 - accuracy: 0.6351 - val_loss: 186.2457 - val_accuracy: 0.5701\n",
      "Epoch 4/15\n",
      "47722/47722 [==============================] - 3s 53us/step - loss: 1.0470 - accuracy: 0.6362 - val_loss: 176.5724 - val_accuracy: 0.5701\n",
      "Epoch 5/15\n",
      "47722/47722 [==============================] - 3s 55us/step - loss: 1.0426 - accuracy: 0.6365 - val_loss: 344.0758 - val_accuracy: 0.5701\n",
      "Epoch 6/15\n",
      "47722/47722 [==============================] - 3s 53us/step - loss: 1.0408 - accuracy: 0.6369 - val_loss: 678.2873 - val_accuracy: 0.5701\n",
      "Epoch 7/15\n",
      "47722/47722 [==============================] - 3s 54us/step - loss: 1.0367 - accuracy: 0.6367 - val_loss: 550.9238 - val_accuracy: 0.5701\n",
      "Epoch 8/15\n",
      "47722/47722 [==============================] - 3s 54us/step - loss: 1.0356 - accuracy: 0.6374 - val_loss: 562.7809 - val_accuracy: 0.5701\n",
      "Epoch 9/15\n",
      "47722/47722 [==============================] - 3s 57us/step - loss: 1.0338 - accuracy: 0.6371 - val_loss: 598.1854 - val_accuracy: 0.5701\n",
      "Epoch 10/15\n",
      "47722/47722 [==============================] - 3s 54us/step - loss: 1.0324 - accuracy: 0.6375 - val_loss: 1640.9417 - val_accuracy: 0.5701\n",
      "Epoch 11/15\n",
      "47722/47722 [==============================] - 3s 54us/step - loss: 1.0309 - accuracy: 0.6377 - val_loss: 1177.4295 - val_accuracy: 0.5701\n",
      "Epoch 12/15\n",
      "47722/47722 [==============================] - 3s 59us/step - loss: 1.0300 - accuracy: 0.6381 - val_loss: 1329.4085 - val_accuracy: 0.5701\n",
      "Epoch 13/15\n",
      "47104/47722 [============================>.] - ETA: 0s - loss: 1.0284 - accuracy: 0.6383"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "epochs = 15\n",
    "history = network.fit(nn_train_x, \n",
    "                      train_y_cat, \n",
    "                      epochs=epochs, \n",
    "                      batch_size=128, \n",
    "                      validation_data=(nn_test_x, test_y_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "test_loss_values = history_dict['val_loss']\n",
    "epochs_range = range(1, epochs + 1)\n",
    "plt.plot(epochs_range, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs_range, test_loss_values, 'ro', label='Test loss')\n",
    "plt.title('Training and test loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_values = history_dict['accuracy']\n",
    "test_acc_values = history_dict['val_accuracy']\n",
    "plt.plot(epochs_range, acc_values, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs_range, test_acc_values, 'ro', label='Test accuracy')\n",
    "plt.title('Training and test accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "pos_count = 0\n",
    "star_cor = 0\n",
    "matrix = [0, 0, 0, 0]\n",
    "preds = network.predict(nn_test_x)\n",
    "for i, row in test_df.iterrows():\n",
    "    if (np.argmax(preds[i]) > 3):\n",
    "        pos_count += 1\n",
    "    if (np.argmax(preds[i]) == np.argmax(test_y_cat[i])):\n",
    "        star_cor += 1\n",
    "    if (np.argmax(preds[i]) > 3 and np.argmax(test_y_cat[i]) > 3):\n",
    "        correct += 1\n",
    "        matrix[0] += 1\n",
    "    elif (np.argmax(preds[i]) <= 3 and np.argmax(test_y_cat[i]) <= 3):\n",
    "        correct += 1\n",
    "        matrix[1] += 1\n",
    "    elif (np.argmax(preds[i]) > 3 and np.argmax(test_y_cat[i]) <= 3):\n",
    "        matrix[2] += 1\n",
    "    elif (np.argmax(preds[i]) <= 3 and np.argmax(test_y_cat[i]) > 3):\n",
    "        matrix[3] += 1\n",
    "\n",
    "print('Correct:', correct, correct / len(test_df))\n",
    "print('Pos:', pos_count, pos_count / len(test_df))\n",
    "print('Star Correct:', star_cor, star_cor / len(test_df))\n",
    "print('True Positive:', matrix[0], matrix[0] / len(test_df))\n",
    "print('True Negative:', matrix[1], matrix[1] / len(test_df))\n",
    "print('False Positive:', matrix[2], matrix[2] / len(test_df))\n",
    "print('False Negative:', matrix[3], matrix[3] / len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network.save('basic_neural_net3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
