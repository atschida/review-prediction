{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>positive</th>\n",
       "      <th>cust_review_count</th>\n",
       "      <th>cust_star_rating_mean</th>\n",
       "      <th>cust_star_rating_std</th>\n",
       "      <th>cust_total_votes_mean</th>\n",
       "      <th>cust_total_votes_std</th>\n",
       "      <th>cust_helpful_votes_mean</th>\n",
       "      <th>cust_helpful_votes_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_3_word_3</th>\n",
       "      <th>neg_1_word_1</th>\n",
       "      <th>neg_1_word_2</th>\n",
       "      <th>neg_1_word_3</th>\n",
       "      <th>neg_2_word_1</th>\n",
       "      <th>neg_2_word_2</th>\n",
       "      <th>neg_2_word_3</th>\n",
       "      <th>neg_3_word_1</th>\n",
       "      <th>neg_3_word_2</th>\n",
       "      <th>neg_3_word_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1617361</td>\n",
       "      <td>849246716</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53052607</td>\n",
       "      <td>849246716</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028547</td>\n",
       "      <td>0.172017</td>\n",
       "      <td>0.084518</td>\n",
       "      <td>0.194290</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>0.052950</td>\n",
       "      <td>0.344210</td>\n",
       "      <td>0.307019</td>\n",
       "      <td>0.363920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15679577</td>\n",
       "      <td>849246716</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>1.505941</td>\n",
       "      <td>7.625000</td>\n",
       "      <td>19.175412</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>17.188036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.371702</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.316641</td>\n",
       "      <td>0.156807</td>\n",
       "      <td>0.052990</td>\n",
       "      <td>0.165214</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>-0.066285</td>\n",
       "      <td>-0.171195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16367779</td>\n",
       "      <td>849246716</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>0.527046</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.364225</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.092906</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25485198</td>\n",
       "      <td>849246716</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.437237</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.392953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_parent  positive  cust_review_count  \\\n",
       "0      1617361       849246716         1                  5   \n",
       "1     53052607       849246716         0                  5   \n",
       "2     15679577       849246716         1                  8   \n",
       "3     16367779       849246716         1                  9   \n",
       "4     25485198       849246716         1                 17   \n",
       "\n",
       "   cust_star_rating_mean  cust_star_rating_std  cust_total_votes_mean  \\\n",
       "0               5.000000              0.000000               0.200000   \n",
       "1               3.600000              0.547723               0.400000   \n",
       "2               3.375000              1.505941               7.625000   \n",
       "3               4.444444              0.527046               0.888889   \n",
       "4               5.000000              0.000000               0.235294   \n",
       "\n",
       "   cust_total_votes_std  cust_helpful_votes_mean  cust_helpful_votes_std  ...  \\\n",
       "0              0.447214                 0.000000                0.000000  ...   \n",
       "1              0.894427                 0.400000                0.894427  ...   \n",
       "2             19.175412                 6.500000               17.188036  ...   \n",
       "3              1.364225                 0.777778                1.092906  ...   \n",
       "4              0.437237                 0.176471                0.392953  ...   \n",
       "\n",
       "   pos_3_word_3  neg_1_word_1  neg_1_word_2  neg_1_word_3  neg_2_word_1  \\\n",
       "0      0.186957      0.000000      0.000000      0.000000      0.000000   \n",
       "1     -0.028547      0.172017      0.084518      0.194290      0.002472   \n",
       "2      0.044000      0.371702      0.000015      0.316641      0.156807   \n",
       "3     -0.171195      0.000000      0.000000      0.000000      0.000000   \n",
       "4      0.249734      0.000000      0.000000      0.000000      0.000000   \n",
       "\n",
       "   neg_2_word_2  neg_2_word_3  neg_3_word_1  neg_3_word_2  neg_3_word_3  \n",
       "0      0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "1      0.006273      0.052950      0.344210      0.307019      0.363920  \n",
       "2      0.052990      0.165214      0.011699     -0.066285     -0.171195  \n",
       "3      0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "4      0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_df2.csv', index_col=0)\n",
    "train_df.drop(['star_rating', 'pos_corpus', 'neg_corpus', 'pos_1', 'pos_2', 'pos_3', \n",
    "               'neg_1', 'neg_2', 'neg_3', 'prod_corpus', 'word_1', 'word_2', 'word_3'], axis=1, inplace=True)\n",
    "#train_df.drop(['cust_total_votes_mean', 'cust_total_votes_std', 'cust_helpful_votes_mean', 'cust_helpful_votes_std', \n",
    "#               'prod_total_votes_mean', 'prod_total_votes_std', 'prod_helpful_votes_mean', 'prod_helpful_votes_std'], \n",
    "#              axis=1, inplace=True)\n",
    "#train_df.drop(['customer_id', 'product_parent', 'cust_review_count',\n",
    "#               'cust_star_rating_mean', 'cust_star_rating_std', 'prod_review_count',\n",
    "#               'prod_star_rating_mean', 'prod_star_rating_std'], \n",
    "#              axis=1, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'product_parent', 'positive', 'cust_review_count',\n",
       "       'cust_star_rating_mean', 'cust_star_rating_std',\n",
       "       'cust_total_votes_mean', 'cust_total_votes_std',\n",
       "       'cust_helpful_votes_mean', 'cust_helpful_votes_std',\n",
       "       'prod_review_count', 'prod_star_rating_mean', 'prod_star_rating_std',\n",
       "       'prod_total_votes_mean', 'prod_total_votes_std',\n",
       "       'prod_helpful_votes_mean', 'prod_helpful_votes_std', 'pos_sim',\n",
       "       'neg_sim', 'pos_1_word_1', 'pos_1_word_2', 'pos_1_word_3',\n",
       "       'pos_2_word_1', 'pos_2_word_2', 'pos_2_word_3', 'pos_3_word_1',\n",
       "       'pos_3_word_2', 'pos_3_word_3', 'neg_1_word_1', 'neg_1_word_2',\n",
       "       'neg_1_word_3', 'neg_2_word_1', 'neg_2_word_2', 'neg_2_word_3',\n",
       "       'neg_3_word_1', 'neg_3_word_2', 'neg_3_word_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive\n",
       "0     9531\n",
       "1    38191\n",
       "dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('positive').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_df[train_df.positive == 0]\n",
    "temp = pd.concat([temp, train_df[train_df.positive == 1][:9531]])\n",
    "train_df = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive\n",
       "0    0.5\n",
       "1    0.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('positive').size() / len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>positive</th>\n",
       "      <th>cust_review_count</th>\n",
       "      <th>cust_star_rating_mean</th>\n",
       "      <th>cust_star_rating_std</th>\n",
       "      <th>cust_total_votes_mean</th>\n",
       "      <th>cust_total_votes_std</th>\n",
       "      <th>cust_helpful_votes_mean</th>\n",
       "      <th>cust_helpful_votes_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_3_word_3</th>\n",
       "      <th>neg_1_word_1</th>\n",
       "      <th>neg_1_word_2</th>\n",
       "      <th>neg_1_word_3</th>\n",
       "      <th>neg_2_word_1</th>\n",
       "      <th>neg_2_word_2</th>\n",
       "      <th>neg_2_word_3</th>\n",
       "      <th>neg_3_word_1</th>\n",
       "      <th>neg_3_word_2</th>\n",
       "      <th>neg_3_word_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36330222</td>\n",
       "      <td>986428010</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>4.291667</td>\n",
       "      <td>1.267629</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.250362</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.049500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>-0.015594</td>\n",
       "      <td>-0.013630</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.023873</td>\n",
       "      <td>-0.029103</td>\n",
       "      <td>-0.046843</td>\n",
       "      <td>-0.041810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24360083</td>\n",
       "      <td>986428010</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>1.191206</td>\n",
       "      <td>1.434783</td>\n",
       "      <td>2.191431</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.537412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901494</td>\n",
       "      <td>-0.222196</td>\n",
       "      <td>-0.196039</td>\n",
       "      <td>-0.217517</td>\n",
       "      <td>0.918800</td>\n",
       "      <td>0.925143</td>\n",
       "      <td>0.901494</td>\n",
       "      <td>0.919331</td>\n",
       "      <td>0.902017</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28891040</td>\n",
       "      <td>437083384</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092532</td>\n",
       "      <td>0.313854</td>\n",
       "      <td>0.086877</td>\n",
       "      <td>0.315884</td>\n",
       "      <td>0.196752</td>\n",
       "      <td>0.052950</td>\n",
       "      <td>0.194290</td>\n",
       "      <td>0.054040</td>\n",
       "      <td>0.014332</td>\n",
       "      <td>-0.002904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52449052</td>\n",
       "      <td>437083384</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1.516575</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>20.789420</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>18.187908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187860</td>\n",
       "      <td>0.083284</td>\n",
       "      <td>-0.115922</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.090283</td>\n",
       "      <td>-0.083403</td>\n",
       "      <td>0.025464</td>\n",
       "      <td>0.084633</td>\n",
       "      <td>-0.092710</td>\n",
       "      <td>0.019767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27192976</td>\n",
       "      <td>437083384</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126235</td>\n",
       "      <td>-0.083963</td>\n",
       "      <td>0.036128</td>\n",
       "      <td>-0.155615</td>\n",
       "      <td>-0.020984</td>\n",
       "      <td>0.021015</td>\n",
       "      <td>-0.042505</td>\n",
       "      <td>0.059809</td>\n",
       "      <td>-0.017769</td>\n",
       "      <td>-0.064662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_parent  positive  cust_review_count  \\\n",
       "0     36330222       986428010         1                 24   \n",
       "1     24360083       986428010         1                 23   \n",
       "2     28891040       437083384         1                 10   \n",
       "3     52449052       437083384         0                  5   \n",
       "4     27192976       437083384         1                  6   \n",
       "\n",
       "   cust_star_rating_mean  cust_star_rating_std  cust_total_votes_mean  \\\n",
       "0               4.291667              1.267629               0.541667   \n",
       "1               4.347826              1.191206               1.434783   \n",
       "2               4.500000              0.707107               0.000000   \n",
       "3               3.400000              1.516575              11.800000   \n",
       "4               4.666667              0.816497               0.500000   \n",
       "\n",
       "   cust_total_votes_std  cust_helpful_votes_mean  cust_helpful_votes_std  ...  \\\n",
       "0              1.250362                 0.333333                1.049500  ...   \n",
       "1              2.191431                 1.000000                1.537412  ...   \n",
       "2              0.000000                 0.000000                0.000000  ...   \n",
       "3             20.789420                10.400000               18.187908  ...   \n",
       "4              1.224745                 0.000000                0.000000  ...   \n",
       "\n",
       "   pos_3_word_3  neg_1_word_1  neg_1_word_2  neg_1_word_3  neg_2_word_1  \\\n",
       "0      0.001941      0.000987     -0.015594     -0.013630      0.006534   \n",
       "1      0.901494     -0.222196     -0.196039     -0.217517      0.918800   \n",
       "2      0.092532      0.313854      0.086877      0.315884      0.196752   \n",
       "3      0.187860      0.083284     -0.115922      0.023810      0.090283   \n",
       "4      0.126235     -0.083963      0.036128     -0.155615     -0.020984   \n",
       "\n",
       "   neg_2_word_2  neg_2_word_3  neg_3_word_1  neg_3_word_2  neg_3_word_3  \n",
       "0      0.007653      0.023873     -0.029103     -0.046843     -0.041810  \n",
       "1      0.925143      0.901494      0.919331      0.902017      1.000000  \n",
       "2      0.052950      0.194290      0.054040      0.014332     -0.002904  \n",
       "3     -0.083403      0.025464      0.084633     -0.092710      0.019767  \n",
       "4      0.021015     -0.042505      0.059809     -0.017769     -0.064662  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_df2.csv', index_col=0)\n",
    "test_df.drop(['star_rating', 'pos_corpus', 'neg_corpus', 'pos_1', 'pos_2', 'pos_3', \n",
    "               'neg_1', 'neg_2', 'neg_3', 'prod_corpus', 'word_1', 'word_2', 'word_3'], axis=1, inplace=True)\n",
    "#test_df.drop(['cust_total_votes_mean', 'cust_total_votes_std', 'cust_helpful_votes_mean', 'cust_helpful_votes_std', \n",
    "#               'prod_total_votes_mean', 'prod_total_votes_std', 'prod_helpful_votes_mean', 'prod_helpful_votes_std'], \n",
    "#              axis=1, inplace=True)\n",
    "#test_df.drop(['customer_id', 'product_parent', 'cust_review_count',\n",
    "#               'cust_star_rating_mean', 'cust_star_rating_std', 'prod_review_count',\n",
    "#               'prod_star_rating_mean', 'prod_star_rating_std'], \n",
    "#              axis=1, inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive\n",
       "0     3573\n",
       "1    12262\n",
       "dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby('positive').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = test_df[test_df.positive == 0]\n",
    "temp = pd.concat([temp, test_df[test_df.positive == 1][:3573]])\n",
    "test_df = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive\n",
       "0    0.5\n",
       "1    0.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby('positive').size() / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.query('positive == 1')) / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train_df.drop('positive', axis=1), train_df['positive']\n",
    "test_x, test_y = test_df.drop('positive', axis=1), test_df['positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7169045619927232"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6991323817520291"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 36 artists>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp_tuples = sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), \n",
    "                 train_x.columns), reverse=False)\n",
    "imp = [t[0] for t in imp_tuples]\n",
    "labl = [t[1] for t in imp_tuples]\n",
    "plt.barh(labl, imp, linewidth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1, weights='distance')\n",
    "knn.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5281276238455079"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5566750629722922"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 3978 0.5566750629722922\n",
      "Pos: 2497 0.34942625244892245\n",
      "Star Correct: 3978 0.5566750629722922\n",
      "True Positive: 1451 0.20305065771060735\n",
      "True Negative: 2527 0.35362440526168487\n",
      "False Positive: 1046 0.14637559473831513\n",
      "False Negative: 2122 0.2969493422893927\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "pos_count = 0\n",
    "star_cor = 0\n",
    "matrix = [0, 0, 0, 0]\n",
    "preds = gnb.predict(test_x)\n",
    "for i in range(len(preds)):\n",
    "    if (preds[i] > 0.5):\n",
    "        pos_count += 1\n",
    "    if (preds[i] == test_y.iloc[i]):\n",
    "        star_cor += 1\n",
    "    if (preds[i] > 0.5 and test_y.iloc[i] > 0.5):\n",
    "        correct += 1\n",
    "        matrix[0] += 1\n",
    "    elif (preds[i] <= 0.5 and test_y.iloc[i] <= 0.5):\n",
    "        correct += 1\n",
    "        matrix[1] += 1\n",
    "    elif (preds[i] > 0.5 and test_y.iloc[i] <= 0.5):\n",
    "        matrix[2] += 1\n",
    "    elif (preds[i] <= 0.5 and test_y.iloc[i] > 0.5):\n",
    "        matrix[3] += 1\n",
    "\n",
    "print('Correct:', correct, correct / len(test_df))\n",
    "print('Pos:', pos_count, pos_count / len(test_df))\n",
    "print('Star Correct:', star_cor, star_cor / len(test_df))\n",
    "print('True Positive:', matrix[0], matrix[0] / len(test_df))\n",
    "print('True Negative:', matrix[1], matrix[1] / len(test_df))\n",
    "print('False Positive:', matrix[2], matrix[2] / len(test_df))\n",
    "print('False Negative:', matrix[3], matrix[3] / len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19062, 36)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                740       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 3,691\n",
      "Trainable params: 3,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(20, activation='relu', input_shape=(36,)))\n",
    "network.add(layers.Dropout(0.5))\n",
    "network.add(layers.Dense(20, activation='relu', input_shape=(20,)))\n",
    "network.add(layers.Dense(20, activation='relu', input_shape=(20,)))\n",
    "network.add(layers.Dense(20, activation='relu', input_shape=(20,)))\n",
    "network.add(layers.Dropout(0.5))\n",
    "network.add(layers.Dense(20, activation='relu', input_shape=(20,)))\n",
    "network.add(layers.Dense(20, activation='relu', input_shape=(20,)))\n",
    "network.add(layers.Dense(10, activation='relu', input_shape=(20,)))\n",
    "network.add(layers.Dropout(0.5))\n",
    "network.add(layers.Dense(10, activation='relu', input_shape=(20,)))\n",
    "network.add(layers.Dense(10, activation='relu', input_shape=(20,)))\n",
    "network.add(layers.Dense(10, activation='relu', input_shape=(20,)))\n",
    "network.add(layers.Dropout(0.5))\n",
    "network.add(layers.Dense(10, activation='relu', input_shape=(20,)))\n",
    "network.add(layers.Dense(10, activation='relu', input_shape=(20,)))\n",
    "network.add(layers.Dense(5, activation='relu', input_shape=(10,)))\n",
    "network.add(layers.Dense(5, activation='relu', input_shape=(10,)))\n",
    "network.add(layers.Dense(1, activation='sigmoid', input_shape=(5,)))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19062 samples, validate on 7146 samples\n",
      "Epoch 1/500\n",
      "19062/19062 [==============================] - 3s 149us/step - loss: 275777.7578 - accuracy: 0.5002 - val_loss: 0.7030 - val_accuracy: 0.5000\n",
      "Epoch 2/500\n",
      "19062/19062 [==============================] - 1s 55us/step - loss: 149.9443 - accuracy: 0.5023 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      "19062/19062 [==============================] - 1s 50us/step - loss: 7.2971 - accuracy: 0.5004 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 1.7840 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 5/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 1.0485 - accuracy: 0.4996 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 6/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.7059 - accuracy: 0.4989 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 7/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6930 - accuracy: 0.4984 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.7150 - accuracy: 0.4941 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.7293 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.8248 - accuracy: 0.4921 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.7979 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      "19062/19062 [==============================] - 1s 49us/step - loss: 0.6931 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6959 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6931 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.7800 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.5010 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.5007 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 22/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 23/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4922 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4957 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6976 - accuracy: 0.4945 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      "19062/19062 [==============================] - 1s 49us/step - loss: 0.7022 - accuracy: 0.5016 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 34/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 1.2436 - accuracy: 0.4958 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 36/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      "19062/19062 [==============================] - 1s 49us/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 38/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 39/500\n",
      "19062/19062 [==============================] - 1s 51us/step - loss: 0.6932 - accuracy: 0.4939 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      "19062/19062 [==============================] - 1s 52us/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4891 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 43/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 44/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4900 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 45/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 46/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.7558 - accuracy: 0.4942 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 47/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 48/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6931 - accuracy: 0.4910 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 49/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4959 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 50/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 51/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 52/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4939 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 53/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 54/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19062/19062 [==============================] - 1s 50us/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 56/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4961 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 57/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 58/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 59/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 60/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 61/500\n",
      "19062/19062 [==============================] - 1s 49us/step - loss: 0.6932 - accuracy: 0.5027 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 62/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 63/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 64/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 65/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 66/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 67/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 68/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 69/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 70/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 71/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 72/500\n",
      "19062/19062 [==============================] - 1s 49us/step - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 73/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4919 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 74/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4999 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 75/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 76/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 77/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6931 - accuracy: 0.4998 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 78/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 79/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 80/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 81/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 82/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 83/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4946 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 84/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4923 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 85/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 86/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 87/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 88/500\n",
      "19062/19062 [==============================] - 1s 51us/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 89/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 90/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4963 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 91/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4954 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 92/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 93/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 94/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.5022 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 95/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 96/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 97/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 98/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 99/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 100/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6935 - accuracy: 0.4957 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 101/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4959 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 102/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 103/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 104/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 105/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 106/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.5018 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 107/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6935 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 108/500\n",
      "19062/19062 [==============================] - 1s 55us/step - loss: 0.6932 - accuracy: 0.4898 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 109/500\n",
      "19062/19062 [==============================] - 1s 56us/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 110/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19062/19062 [==============================] - 1s 53us/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 111/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 112/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 113/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 114/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 115/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4923 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 116/500\n",
      "19062/19062 [==============================] - 1s 52us/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 117/500\n",
      "19062/19062 [==============================] - 1s 50us/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 118/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4999 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 119/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 120/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4942 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 121/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 122/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 123/500\n",
      "19062/19062 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.49 - 1s 45us/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 124/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 125/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4939 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 126/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 127/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 128/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 129/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 130/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4949 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 131/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.5023 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 132/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4954 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 133/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 134/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 135/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 136/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4959 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 137/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 138/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 139/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 140/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 141/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 142/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 143/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 144/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 145/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 146/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4949 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 147/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 148/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 149/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 150/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4926 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 151/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 152/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 153/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 154/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 155/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 156/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 157/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4949 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 158/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.5023 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 159/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4948 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 160/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 161/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 162/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 163/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 165/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 166/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 167/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 168/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 169/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 170/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 171/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4908 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 172/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 173/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4963 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 174/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 175/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 176/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 177/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 178/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 179/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 180/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 181/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 182/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 183/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 184/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 185/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 186/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4946 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 187/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 188/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 189/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 190/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.5026 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 191/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4936 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 192/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 193/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4999 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 194/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4999 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 195/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 196/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 197/500\n",
      "19062/19062 [==============================] - 1s 54us/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 198/500\n",
      "19062/19062 [==============================] - 1s 53us/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 199/500\n",
      "19062/19062 [==============================] - 1s 51us/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 200/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4921 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 201/500\n",
      "19062/19062 [==============================] - 1s 52us/step - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 202/500\n",
      "19062/19062 [==============================] - 1s 52us/step - loss: 0.6932 - accuracy: 0.4918 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 203/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 204/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 205/500\n",
      "19062/19062 [==============================] - 1s 51us/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 206/500\n",
      "19062/19062 [==============================] - 1s 51us/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 207/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4891 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 208/500\n",
      "19062/19062 [==============================] - 1s 50us/step - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 209/500\n",
      "19062/19062 [==============================] - 1s 50us/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 210/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 211/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 212/500\n",
      "19062/19062 [==============================] - 1s 49us/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 213/500\n",
      "19062/19062 [==============================] - 1s 52us/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 214/500\n",
      "19062/19062 [==============================] - 1s 61us/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 215/500\n",
      "19062/19062 [==============================] - 1s 60us/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 216/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 217/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 218/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4912 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 220/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 221/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 222/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 223/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4896 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 224/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 225/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 226/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 227/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4927 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 228/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 229/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 230/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 231/500\n",
      "19062/19062 [==============================] - 1s 49us/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 232/500\n",
      "19062/19062 [==============================] - 1s 51us/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 233/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4932 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 234/500\n",
      "19062/19062 [==============================] - 1s 50us/step - loss: 0.6950 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 235/500\n",
      "19062/19062 [==============================] - 1s 49us/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 236/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 237/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 238/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4927 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 239/500\n",
      "19062/19062 [==============================] - 1s 49us/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 240/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 241/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 242/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 243/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 244/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4932 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 245/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 246/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 247/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 248/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 249/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 250/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 251/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6934 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 252/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 253/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 254/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 255/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 256/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 257/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4941 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 258/500\n",
      "19062/19062 [==============================] - 1s 49us/step - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 259/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 260/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 261/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 262/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 263/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 264/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 265/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 266/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 267/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 268/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 269/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 270/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 271/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 272/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 273/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 274/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 275/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 276/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 277/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 278/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4909 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 279/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 280/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 281/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 282/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 283/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 284/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4957 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 285/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 286/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 287/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 288/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 289/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 290/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4949 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 291/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 292/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 293/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 294/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 295/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 296/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4957 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 297/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4921 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 298/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 299/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.8041 - accuracy: 0.4996 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 300/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4957 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 301/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 302/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 303/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 304/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 305/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4964 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 306/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 307/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 308/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 309/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4941 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 310/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 311/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 312/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 313/500\n",
      "19062/19062 [==============================] - 1s 49us/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 314/500\n",
      "19062/19062 [==============================] - 1s 49us/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 315/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 316/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 317/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4949 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 318/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 319/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 320/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 321/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 322/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 323/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 324/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 325/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4964 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 326/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 327/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 329/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 330/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 331/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 332/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4913 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 333/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 334/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 335/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 336/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 337/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 338/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4963 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 339/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 340/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 341/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 342/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 343/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4963 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 344/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 345/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 346/500\n",
      "19062/19062 [==============================] - 1s 51us/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 347/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 348/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4954 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 349/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 350/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 351/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 352/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 353/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 354/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 355/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 356/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4946 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 357/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 358/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 359/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5014 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 360/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4999 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 361/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 362/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4946 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 363/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 364/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 365/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 366/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 367/500\n",
      "19062/19062 [==============================] - 1s 50us/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 368/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6931 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 369/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 370/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 371/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 372/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 373/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 374/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 375/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 376/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 377/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 378/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 379/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 380/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 381/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 382/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4999 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 383/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 384/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 385/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4942 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 386/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 387/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 388/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6931 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 389/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4934 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 390/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4923 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 391/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4932 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 392/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 393/500\n",
      "19062/19062 [==============================] - 1s 53us/step - loss: 0.6944 - accuracy: 0.4912 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 394/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 395/500\n",
      "19062/19062 [==============================] - 1s 52us/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 396/500\n",
      "19062/19062 [==============================] - 1s 49us/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 397/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4999 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 398/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 399/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 400/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 401/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 402/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 403/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4999 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 404/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 405/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 406/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 407/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 408/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 409/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 410/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 411/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 412/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 413/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 414/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4916 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 415/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4921 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 416/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 417/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 418/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 419/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 420/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 421/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 422/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 423/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 424/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 425/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 426/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 427/500\n",
      "19062/19062 [==============================] - 1s 49us/step - loss: 0.6932 - accuracy: 0.4959 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 428/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 429/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6947 - accuracy: 0.4925 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 430/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4922 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 431/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 432/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 433/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 434/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 435/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 436/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4959 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 438/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 439/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6931 - accuracy: 0.5018 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 440/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4964 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 441/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 442/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 443/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 444/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 445/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 446/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 447/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 448/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 449/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 450/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 451/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 452/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 453/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 454/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 455/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 456/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 457/500\n",
      "19062/19062 [==============================] - 1s 49us/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 458/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4907 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 459/500\n",
      "19062/19062 [==============================] - 1s 48us/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 460/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 461/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 462/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4919 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 463/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 464/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 465/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 466/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 467/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6941 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 468/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 469/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 470/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4929 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 471/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 472/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 473/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 474/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 475/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 476/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 477/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 478/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 479/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4905 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 480/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 481/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 482/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 483/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 484/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 485/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 486/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 487/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 488/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 489/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4964 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 490/500\n",
      "19062/19062 [==============================] - 1s 47us/step - loss: 0.6932 - accuracy: 0.4948 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 491/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4912 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 492/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 493/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 494/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 495/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6931 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 496/500\n",
      "19062/19062 [==============================] - 1s 43us/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 497/500\n",
      "19062/19062 [==============================] - 1s 46us/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 498/500\n",
      "19062/19062 [==============================] - 1s 45us/step - loss: 0.6932 - accuracy: 0.4916 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 499/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4948 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 500/500\n",
      "19062/19062 [==============================] - 1s 44us/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "epochs = 500\n",
    "history = network.fit(train_x, \n",
    "                      train_y, \n",
    "                      epochs=epochs, \n",
    "                      batch_size=128, \n",
    "                      validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "test_loss_values = history_dict['val_loss']\n",
    "epochs_range = range(1, epochs + 1)\n",
    "plt.plot(epochs_range, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs_range, test_loss_values, 'ro', label='Test loss')\n",
    "plt.title('Training and test loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_values = history_dict['accuracy']\n",
    "test_acc_values = history_dict['val_accuracy']\n",
    "plt.plot(epochs_range, acc_values, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs_range, test_acc_values, 'ro', label='Test accuracy')\n",
    "plt.title('Training and test accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 3573 0.5\n",
      "Pos: 7146 1.0\n",
      "Star Correct: 0 0.0\n",
      "True Positive: 3573 0.5\n",
      "True Negative: 0 0.0\n",
      "False Positive: 3573 0.5\n",
      "False Negative: 0 0.0\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "pos_count = 0\n",
    "star_cor = 0\n",
    "matrix = [0, 0, 0, 0]\n",
    "preds = network.predict(test_x)\n",
    "for i in range(len(preds)):\n",
    "    if (preds[i] > 0.5):\n",
    "        pos_count += 1\n",
    "    if (preds[i] == test_y.iloc[i]):\n",
    "        star_cor += 1\n",
    "    if (preds[i] > 0.5 and test_y.iloc[i] > 0.5):\n",
    "        correct += 1\n",
    "        matrix[0] += 1\n",
    "    elif (preds[i] <= 0.5 and test_y.iloc[i] <= 0.5):\n",
    "        correct += 1\n",
    "        matrix[1] += 1\n",
    "    elif (preds[i] > 0.5 and test_y.iloc[i] <= 0.5):\n",
    "        matrix[2] += 1\n",
    "    elif (preds[i] <= 0.5 and test_y.iloc[i] > 0.5):\n",
    "        matrix[3] += 1\n",
    "\n",
    "print('Correct:', correct, correct / len(test_df))\n",
    "print('Pos:', pos_count, pos_count / len(test_df))\n",
    "print('Star Correct:', star_cor, star_cor / len(test_df))\n",
    "print('True Positive:', matrix[0], matrix[0] / len(test_df))\n",
    "print('True Negative:', matrix[1], matrix[1] / len(test_df))\n",
    "print('False Positive:', matrix[2], matrix[2] / len(test_df))\n",
    "print('False Negative:', matrix[3], matrix[3] / len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network.save('basic_neural_net3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
